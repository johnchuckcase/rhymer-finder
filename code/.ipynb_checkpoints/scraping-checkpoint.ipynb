{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import library to read urls\n",
    "from urllib2 import urlopen\n",
    "# Import library to parse html\n",
    "from bs4 import BeautifulSoup\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "# Access/Initiate Database\n",
    "db = client['rap_db']\n",
    "# Access/Initiate Table\n",
    "tab = db['lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artists = ['dmx','toohort','pablo','masterp','50cent','drake','bone','saltnpepa',\\\n",
    "           'juvenile','youngjeezy','wizkhalifa','lilb','lilwayne','guccimane','missy',\\\n",
    "           'west','rundmc','ugk','snoopdogg','jadakiss','scarface','icp','nickiminaj',\\\n",
    "          'three6mafia','getoboys','ti','camron','bizmarkie','icecube','nelly','game',\\\n",
    "          'lupefiasco','lilkim','jayz','clipse','icet','puffdaddy','royceda59','eminem',\\\n",
    "          'cypress','krsone','mosdef','rakim','tribecalledquest','tyga','fatjoe',\\\n",
    "          'publicenemy','kweli','brotherali','twista','llcoolj','mobbdeep','ludacris',\\\n",
    "           'gangstarr','goodiemob','techn9ne','busta','wale','delasoul','methodman',\\\n",
    "          'common','raekwon','xzibit','beastie','nas','outkast','e40','blackalicious',\\\n",
    "          'redman','ghostface','roots','wutang','rza','canibus','gza','aesoprock',\\\n",
    "          'jcole','kendricklamar']\n",
    "# 19/50cent.html\n",
    "# 19/2pac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johncase/anaconda/lib/python2.7/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "#Gather all song links for particular artist\n",
    "\n",
    "artist = '2pac'\n",
    "\n",
    "if artist[0].isdigit():\n",
    "    url = 'http://www.azlyrics.com/19/' + artist + '.html'\n",
    "else:\n",
    "    url = 'http://www.azlyrics.com/' + artist[0] + '/' + artist + '.html'\n",
    "    \n",
    "content = urlopen(url).read()\n",
    "# Feed the html to a BeatifulSoup object\n",
    "soup = BeautifulSoup(content)\n",
    "els = soup.find(id='listAlbum')\n",
    "\n",
    "#Do not include song lyrics from \"non-rap\" songs or repeats (e.g., remixes)\n",
    "stop_strings = ['intro','skit','interlude','remix']\n",
    "\n",
    "#Parse out urls\n",
    "urls = [x['href'][2:] for x in els.find_all(target='_blank') if not any(substr in x.contents[0].lower() for substr in stop_strings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, url in enumerate(urls):\n",
    "    \n",
    "    print i, url\n",
    "    \n",
    "    # Go to the link and get the html as a string\n",
    "    content = urlopen('http://www.azlyrics.com/' + url).read()\n",
    "    # Feed the html to a BeatifulSoup object\n",
    "    soup = BeautifulSoup(content)\n",
    "\n",
    "    # Extract the rows in the table\n",
    "    rows = soup.find('div',{'class':'col-xs-12 col-lg-8 text-center'})\n",
    "    rows = rows.find('div',{'class':''})\n",
    "    text = rows.text\n",
    "    a = re.split(r'\\[?\\:?]?',text)\n",
    "\n",
    "    time.sleep(5)\n",
    "    time.sleep(np.random.rand()*10)\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        time.sleep(5)\n",
    "        time.sleep(np.random.rand()*10)     \n",
    "    \n",
    "    lyrics = ''\n",
    "    for t in a:\n",
    "        if len(t) > 100:\n",
    "            lyrics = lyrics + t.strip().encode('ascii','ignore')\n",
    "    tab.insert_one({'artist':artist, 'url':url, 'lyrics':lyrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export to JSON\n",
    "\n",
    "# import pymongo\n",
    "# from bson.json_util import dumps\n",
    "# import json\n",
    "# import pickle\n",
    "\n",
    "# # connection = pymongo.Connection(\"localhost\", 27017)\n",
    "# # db = connection.mydocs\n",
    "\n",
    "# def get():\n",
    "#     cursor = tab.find()\n",
    "#     return dumps(cursor)\n",
    "# raps = json.loads(get())\n",
    "\n",
    "# import cPickle as pickle\n",
    "# with open(\"rap_data.json\", 'w') as f:\n",
    "#     pickle.dump(raps, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
